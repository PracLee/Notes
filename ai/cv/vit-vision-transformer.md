# ViT (Vision Transformer)

CNN의 결정적인 한계점은 바로 앞서 비유했던 \*\*"돋보기(작은 필터)로만 세상을 본다"\*\*는 그 구조 자체에서 나옵니다.

학술적인 용어로는 Receptive Field(수용 영역)의 한계와 Inductive Bias(귀납적 편향)의 고정성 때문인데, 이걸 쉽게 풀어서 3가지 핵심 이유로 설명해 드릴게요.

***

#### 1. "나무만 보고 숲을 못 본다" (지역성 한계)

이게 가장 큰 이유입니다. CNN은 태생적으로 \*\*"내 주변(Local)"\*\*만 볼 수 있습니다.

* CNN의 답답함:
  * 이미지 왼쪽 끝에 '강아지 얼굴'이 있고, 오른쪽 끝에 '강아지 꼬리'가 있다고 칩시다.
  * CNN의 돋보기($$ $3 \times 3$ $$)는 이 둘을 한 번에 보지 못합니다.
  * 층을 아주 많이 쌓아서(Deep), 정보가 위로 올라가고 합쳐져야 비로소 "아, 얼굴과 꼬리가 연결된 거구나"라고 뒤늦게 깨닫습니다.
* ViT의 해결책 (Global Context):
  * Transformer의 Self-Attention은 거리 제한이 없습니다.
  * 첫 번째 층에서부터 \*\*'얼굴 패치'\*\*가 \*\*'꼬리 패치'\*\*를 바로 참조합니다.
  * \*\*"이미지 전체의 문맥(Global Context)"\*\*을 처음부터 파악하고 들어갑니다.

> 비유:
>
> CNN: 퍼즐 조각을 하나씩 들고 "이건 파란색이네", "이건 빨간색이네" 하다가 나중에야 전체 그림을 아는 방식.
>
> ViT: 퍼즐판 전체를 쫙 펼쳐놓고, "이 조각은 저기 구석 조각이랑 색깔이 비슷하네?"라며 멀리 떨어진 관계를 바로 파악하는 방식.

#### 2. "중요한 것과 안 중요한 것을 똑같이 취급한다" (고정된 가중치)

CNN의 필터는 한 번 학습되면 이미지의 어느 부분을 보든 똑같은 방식으로 작동합니다.

* CNN의 답답함:
  * 이미지 속에 '복잡한 사람 얼굴'이 있든, '단순한 파란 하늘'이 있든 똑같은 필터로 똑같이 훑고 지나갑니다.
  * "하늘은 대충 보고 얼굴에 집중해!"라는 유동적인 대처가 어렵습니다. (물론 학습을 통해 얼굴에 반응하는 필터가 생기지만, 메커니즘 자체가 고정적입니다.)
* ViT의 해결책 (Dynamic Attention):
  * Attention 메커니즘은 입력 데이터에 따라 가중치가 변합니다.
  * "이 패치는 중요하니까 가중치를 0.9 주고, 저 패치는 배경이니까 0.1만 줘야지" 하는 식의 동적인(Dynamic) 집중이 가능합니다.

#### 3. "틀에 박힌 사고방식" (Inductive Bias의 역설)

CNN은 태어날 때부터 \*\*"가까운 픽셀끼리는 친하다(Locality)"\*\*라는 강력한 고정관념(Inductive Bias)을 가지고 설계되었습니다.

* CNN의 답답함:
  * 데이터가 적을 때는 이 고정관념이 정답을 빨리 찾는 가이드라인 역할을 해서 아주 좋습니다. (그래서 적은 데이터로도 학습이 잘 됨)
  * 하지만 데이터가 \*\*수억 장(Big Data)\*\*이 넘어가면, 이 고정관념이 오히려 \*\*성능의 천장(Limit)\*\*을 만듭니다. AI가 더 창의적으로 패턴을 찾을 수 있는데, "아니야, 가까운 것부터 봐!"라고 강요하는 꼴이니까요.
* ViT의 해결책:
  * ViT는 그런 고정관념이 없습니다. (백지상태)
  * 처음엔 멍청해 보이지만, 초대형 데이터를 때려 박으면 편견 없이 데이터 그 자체의 패턴을 흡수하여 CNN의 성능을 아득히 뛰어넘습니다.

***

#### 요약: ViT가 등장한 이유

결국 CNN은 \*\*"부분을 합쳐 전체를 보는 방식"\*\*이라서, \*\*"멀리 떨어진 정보들의 관계"\*\*를 파악하는 데 비효율적이었습니다.

자연어 처리(NLP)에서 Transformer가 문장 전체의 단어 관계를 기가 막히게 파악하는 걸 보고, 연구자들이 생각한 거죠.

> "야, 그림도 문장처럼 쪼개서 Transformer에 넣으면, CNN처럼 좁게 안 보고 전체를 시원하게 보지 않을까?"

이 아이디어가 성공한 것이 바로 ViT입니다.

***

이해를 돕기 위한 질문:

이제 ViT가 "이미지를 어떻게 문장처럼 쪼개서(Patch)" 넣는지, 그 구체적인 과정(Patch Embedding)을 설명해 드릴까요? BERT랑 아주 비슷해서 금방 이해하실 거예요!
