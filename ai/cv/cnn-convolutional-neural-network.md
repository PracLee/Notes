# CNN (Convolutional Neural Network)

## 1. 탄생배경

* ### **"기존 인공지능이 이미지를 다루는 방식이 너무 멍청하다."** 라는 개념에서 시작
  * 기존 인공지능에게 그림을 전달하는 방식
    *   28 \* 28 크기의 이미지를 전달할때 (784개)

        ➡️ 2차원 그림을 1줄로 Flatten 하여 전달&#x20;

        ➡️ 그림의 위치정보가 사라지는 문제 발생

        ➡️ 픽셀끼리 뭉쳐있어야 의미가 있는 것을 이해 못하고, 단순 독립숫자 784개로 인식
  *   생물학적 영감: "고양이는 세상을 어떻게 볼까?" (1959년)

      *   고양이에게 다양한 이미지를 보여주며, 어느 뉴런이 반응하는지 측정

          ➡️ 고양이는 그림 전체를 한번에 인식하는 것이 아님

          ➡️ 어떤 뉴런은 수직선(|) 에만 반응, 또 다른 뉴런은 수평선(ㅡ)을 볼땜만 반응

          ➡️ 이 단순한 정보들이 뇌의 뒷부분으로 가면서 복잡한 모양 인식

      ➡️  전체적으로 보는게 아니라, **작은 특징(선, 모서리)를 먼저 찾고 합쳐서** 인식
  *   CNN의 탄생: 인간의 뇌를 흉내 내자(1980\~90년대, 얀 르쿤(Yann LeCun) 교수)

      * 아이디어: 이미지를  한 줄로 Flatten 하지 말자
        * 이미지의 2차원 형태 (H \* X) 를 그대로 유지
        *   고양이 실험처럼 **작은 필터(돋보기)** 가 이미지를 훑으면서 '가로선', '세로선' 같은 특징만 추출

            ➡️ **Convolution(합성곱)**
        * 추출한 특징을 모아서 점차 복잡한 모양을 인식

      ➡️ 초기 CNN인 **LeNet 출현**
  *   **대폭발: AlexNet의 등장 (2012년)**

      * 90년대 컴퓨터는 너무 느려서, 우편번호 같은 작은 흑백 이미지만 처리 가능
      * 이미지넷(ImageNet, 이미지 인식 대회) 에서 **AlexNet**의 등장
        * 보통 에러율이 26%
        *   **깊은 층을 가진 CNN**이 GPU를 사용하여 연산처리

            ➡️ 에러율을 16%로 뚝 떨어뜨리며 압도적인 1등

      ➡️ **"이미지 처리는 무조건 CNN이다"** 라는 인식 생성&#x20;

      ➡️ 알파고나 자율주행차의 눈이 이 CNN 기술을 바탕으로 발전



## 2. 핵심 개념

* ### Local Connectivity (지역 연결)
  * 이미지의 의미 **가까운 픽셀들의 조합**에서 도출
  * CNN은 한 뉴런이 입력 전체를 보지 않고, **작은 영역(예: 3×3, 5×5)** 만 확인
  * 효과: 불필요한 연결을 줄여 **파라미터 수 감소**, 학습이 안정적.
* ### Weight Sharing (가중치 공유)
  * 같은 필터(커널)를 이미지의 여러 위치에 **반복 적용**
  * “왼쪽 위에서 찾는 세로선”과 “오른쪽 아래에서 찾는 세로선”은 같은 패턴이므로 **같은 검출기**를 쓰는 게 합리적.
  * 효과:
    * 데이터가 조금 부족해도 일반화에 유리
    * 위치가 달라도 같은 특징을 잡을 수 있음
* ### Translation Equivariance (이동 등가성)
  * 입력 이미지가 오른쪽으로 조금 이동하면, 컨볼루션 결과(feature map)도 **같이 이동**
  * 즉, CNN은 “패턴이 어디에 있든” **비슷한 형태로 반응**
  * 주의:
    * 이건 **불변성(invariance)**&#xC774; 아니라 **등가성(equivariance)**
    * 완전 불변성은 보통 pooling/다운샘플링/데이터 증강으로 “근사적으로” 확보
* ### Receptive Field (수용영역)와 계층적 특징
  * 얕은 층: 엣지/선/코너 같은 **저수준 특징**
  * 깊은 층: 텍스처/부품/형태/객체 같은 **고수준 특징**
  * 층이 깊어질수록 각 뉴런이 “참조하는 입력 범위(수용영역)”가 넓어져, **부분→전체**로 조립되는 인식 가능
* ### Channel(채널)과 Feature Map(특징맵)
  * 컨볼루션 필터 하나 ➡️ **하나의 특징맵(feature map)**
  * 필터를 여러 개 쓰면 채널 확대(예: 64개 필터 ➡️ 64채널)
  * 모델은 “엣지 검출기 64종”처럼 **여러 종류의 특징**을 병렬 학습
  * RGB 입력의 경우 필터는 3채널을 동시에 보며(3×3×3), 결과는 2D 특징맵 1장을 출력

