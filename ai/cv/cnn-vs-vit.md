# CNN vs Vit

* ViT가 등장했을 때 다들 "이제 CNN은 끝났다"라고 생각했지만, 몇 년이 지난 지금도 CNN은 여전히 현역이며 건재
  * 이유는 **"가성비"**&#xC640; "환경" 때문
  * 쉽게 비유하자면 **CNN은 "노련한 기술자"**&#xC774;고, **ViT는 "천재형 연구원"**
  * 상황에 따라 어떤 것을 써야 할지가 명확히 차이가 남

***

## 1. "데이터 헝그리" (Data Efficiency)

### ViT의 가장 큰 약점입니다. ViT는 데이터가 엄청나게 많아야 함

* ViT (천재형): "나한테 사전 지식(Inductive Bias) 따윈 주지 마. 대신 교과서 **3억 권(JFT-300M)**&#xC744; 주면 내가 스스로 우주의 진리를 깨우칠게."
  * 데이터가 적으면 과적합(Overfitting)되거나 학습이 안 됨
* CNN (노련한 기술자): "난 '이미지란 원래 이런 거야'라는 기본 상식(Inductive Bias)을 갖고 있어. 교과서 **1,000권(ImageNet-1k)**&#xB9CC; 줘도 충분히 잘해."
  *   대부분의 프로젝트는 데이터가 부족 (희귀병 엑스레이, 공장 불량품 사진 등)

      ➡️ CNN이 압도적으로 유리

#### 2. 고해상도 이미지 처리 (Resolution)

이미지가 커질수록 ViT는 연산량이 기하급수적으로 폭발

* CNN: 이미지가 2배 커지면, 연산량도 대충 2배 늘어납니다. (선형적)
* ViT: 이미지가 커지면 패치(조각) 개수가 늘어나죠? 모든 패치가 서로서로 인사를 나눠야(Self-Attention) 합니다. 패치가 2배 늘어나면 연산량은 \*\*4배($$ $N^2$ $$)\*\*로 늘어납니다. (이차적)
  * $$ $\rightarrow$ $$ 의료 영상이나 위성 사진 같은 초고해상도 이미지를 처리할 때 ViT는 메모리가 터져버리기 쉽습니다.

#### 3. "빠릿빠릿함"과 온디바이스 AI (Inference Speed)

스마트폰이나 자율주행차, CCTV 같은 \*\*엣지 디바이스(Edge Device)\*\*에서는 속도와 전력 소모가 생명입니다.

* CNN: 구조가 단순하고 메모리를 적게 먹어서 모바일 기기에 최적화하기 좋습니다. (하드웨어 가속도 잘 받습니다.)
* ViT: 무거운 행렬 연산(Attention) 때문에 속도가 느리고 배터리를 많이 잡아먹습니다. 실시간으로 빠르게 처리해야 하는 상황에서는 CNN이 더 빠릅니다.

#### 4. 학습의 안정성 (Stability)

ViT는 학습시키기가 까다롭습니다. 하이퍼파라미터(학습률, Optimizer 설정 등)에 매우 민감해서, 세팅을 조금만 잘못해도 학습이 발산해버립니다. 반면 CNN은 대충 돌려도 웬만하면 결과가 잘 나옵니다.

***

#### 핵심 요약: 언제 무엇을 써야 할까?

| **상황**                   | **추천 모델**                  | **이유**                               |
| ------------------------ | -------------------------- | ------------------------------------ |
| 데이터가 적을 때 (수천\~수만 장)     | CNN (ResNet, EfficientNet) | 적은 데이터로도 학습이 잘 됨 (Inductive Bias 덕분) |
| 데이터가 엄청 많을 때 (수천만\~수억 장) | ViT                        | 데이터의 한계를 뚫고 성능이 계속 오름                |
| 스마트폰/임베디드 탑재             | CNN (MobileNet)            | 가볍고 빠르며 배터리 소모가 적음                   |
| 고해상도 이미지                 | CNN                        | 연산 효율이 좋음                            |
| 전역적 문맥 파악이 중요할 때         | ViT                        | 이미지 전체 관계를 한 번에 파악함                  |

#### 결론: 요즘 트렌드는 "하이브리드"

그래서 요즘 연구자들은 \*\*"CNN의 효율성 + ViT의 전역적 시야"\*\*를 섞기 시작했습니다.

* 초반부: CNN을 써서 이미지의 자잘한 특징을 빠르게 추출하고 사이즈를 줄입니다.
* 후반부: 작아진 특징 맵을 ViT(Transformer)에 넣어서 전체적인 관계를 파악합니다.

이렇게 하면 "적은 데이터로도 학습이 잘 되고(CNN 장점), 전체 맥락도 잘 보는(ViT 장점)" 모델이 되니까요! (예: CoAtNet, LeViT 등)

***

이해가 쏙쏙 되시나요?

이제 CNN과 ViT의 관계가 "경쟁자"라기보다는 "상호 보완적인 도구"라는 느낌이 드실 겁니다.

혹시 "그럼 ViT는 구체적으로 이미지를 어떻게 쪼개서 넣는다는 거야?" (패치 임베딩 과정)가 궁금하시다면 이어서 설명해 드릴 수 있습니다.
