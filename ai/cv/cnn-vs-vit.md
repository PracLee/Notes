# CNN vs Vit

* ViT가 등장했을 때 다들 "이제 CNN은 끝났다"라고 생각했지만, 몇 년이 지난 지금도 CNN은 여전히 현역이며 건재
  * 이유는 **"가성비"**&#xC640; "환경" 때문
  * 쉽게 비유하자면 **CNN은 "노련한 기술자"**&#xC774;고, **ViT는 "천재형 연구원"**
  * 상황에 따라 어떤 것을 써야 할지가 명확히 차이가 남

***

## 1. "데이터 헝그리" (Data Efficiency)

### ViT의 가장 큰 약점입니다. ViT는 데이터가 엄청나게 많아야 함

* ViT (천재형): "나한테 사전 지식(Inductive Bias) 따윈 주지 마. 대신 교과서 **3억 권(JFT-300M)**&#xC744; 주면 내가 스스로 우주의 진리를 깨우칠게."
  * 데이터가 적으면 과적합(Overfitting)되거나 학습이 안 됨
* CNN (노련한 기술자): "난 '이미지란 원래 이런 거야'라는 기본 상식(Inductive Bias)을 갖고 있어. 교과서 **1,000권(ImageNet-1k)**&#xB9CC; 줘도 충분히 잘해."
  *   대부분의 프로젝트는 데이터가 부족 (희귀병 엑스레이, 공장 불량품 사진 등)

      ➡️ CNN이 압도적으로 유리

#### 2. 고해상도 이미지 처리 (Resolution)

이미지가 커질수록 ViT는 연산량이 기하급수적으로 폭발

* CNN: 이미지가 2배 커지면, 연산량도 대충 2배 늘어남 (선형적)
*   ViT: 이미지가 커지면 패치(조각) 개수가 늘어남&#x20;

    ➡️ 패치가 서로서로 Self-Attention

    ➡️ 패치가 2배 늘어나면 연산량은 **4배(n \*\* 2)**&#xB85C; 늘어남 (이차적)

    ➡️ 의료 영상이나 위성 사진 같은 초고해상도 이미지를 처리할 때 ViT는 불리

#### 3. "빠릿빠릿함"과 온디바이스 AI (Inference Speed)

스마트폰이나 자율주행차, CCTV 같은 **엣지 디바이스(Edge Device)**&#xC5D0;서는 속도와 전력 소모가 생명

* CNN: 구조가 단순하고 메모리를 적게 먹어서 모바일 기기에 최적화 (하드웨어 가속도 우수)
*   ViT: 무거운 행렬 연산(Attention) 때문에 속도가 느리고 배터리를 많이 먹음

    ➡️ 실시간으로 빠르게 처리해야 하는 상황에서는 CNN이 강점

#### 4. 학습의 안정성 (Stability)

* ViT는 하이퍼파라미터(학습률, Optimizer 설정 등)에 매우 민감해서, 세팅을 조금만 잘못해도 학습이 발산
* 반면 CNN은 대충 돌려도 웬만하면 의미있는 결과 도출

***

#### 핵심 요약: 언제 무엇을 써야 할까?

| **상황**                   | **추천 모델**                  | **이유**                               |
| ------------------------ | -------------------------- | ------------------------------------ |
| 데이터가 적을 때 (수천\~수만 장)     | CNN (ResNet, EfficientNet) | 적은 데이터로도 학습이 잘 됨 (Inductive Bias 덕분) |
| 데이터가 엄청 많을 때 (수천만\~수억 장) | ViT                        | 데이터의 한계를 뚫고 성능이 계속 오름                |
| 스마트폰/임베디드 탑재             | CNN (MobileNet)            | 가볍고 빠르며 배터리 소모가 적음                   |
| 고해상도 이미지                 | CNN                        | 연산 효율이 좋음                            |
| 전역적 문맥 파악이 중요할 때         | ViT                        | 이미지 전체 관계를 한 번에 파악함                  |

#### 결론: 요즘 트렌드는 "하이브리드"

연구자들은 **"CNN의 효율성 + ViT의 전역적 시야"**&#xB97C; 함께 사용

* 초반부: CNN을 써서 이미지의 자잘한 특징을 빠르게 추출하고 사이즈 축소
* 후반부: 작아진 특징 맵을 ViT(Transformer)에 넣어서 전체적인 관계를 파악

➡️ "적은 데이터로도 학습이 잘 되고(CNN 장점), 전체 맥락도 잘 보는(ViT 장점)" 모델 (예: CoAtNet, LeViT 등)

